% LaTeX template for Artifact Evaluation V20201122
%
% Prepared by 
% * Grigori Fursin (cTuning foundation, France) 2014-2020
% * Bruce Childers (University of Pittsburgh, USA) 2014
%
% See examples of this Artifact Appendix in
%  * SC'17 paper: https://dl.acm.org/citation.cfm?id=3126948
%  * CGO'17 paper: https://www.cl.cam.ac.uk/~sa614/papers/Software-Prefetching-CGO2017.pdf
%  * ACM ReQuEST-ASPLOS'18 paper: https://dl.acm.org/citation.cfm?doid=3229762.3229763
%
% (C)opyright 2014-2020
%
% CC BY 4.0 license
%

\documentclass{sigplanconf}

\usepackage{hyperref}

\begin{document}

\special{papersize=8.5in,11in}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% When adding this appendix to your paper, 
% please remove above part
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix
\section{Artifact Appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Abstract}

% {\em Obligatory}

\subsection{Artifact check-list (meta-information)}

% {\em Obligatory. Use just a few informal keywords in all fields applicable to your artifacts
% and remove the rest. This information is needed to find appropriate reviewers and gradually 
% unify artifact meta information in Digital Libraries.}

A SPEC2017 benchmark suite is needed for this Artifact Evaluation.

{\small
\begin{itemize}
  % \item {\bf Algorithm: }
  % \item {\bf Program: }
  \item {\bf Compilation: GCC and binary rewriting tools.}
  \item {\bf Transformations: Binary rewriting using Dyninst.}
  \item {\bf Binary: Linux ELF.}
  % \item {\bf Model: }
  % \item {\bf Data set: }
  \item {\bf Run-time environment: Root access to Ubuntu Linux. We recommend Ubuntu Bionic 18.04.}
  % \item {\bf Hardware: }
  % \item {\bf Run-time state: }
  % \item {\bf Execution: }
  \item {\bf Metrics: We use execution time as one of the metrics.}
  \item {\bf Output: For SPEC2017 benchmark, the results are printed into a text file. For web-browser-based benchmarks, results are shown on the browser.}
  \item {\bf Experiments: Using Bash scripts and Linux commands.}
  \item {\bf How much disk space required (approximately)?: 5GB.}
  \item {\bf How much time is needed to prepare workflow (approximately)?: One hour.}
  \item {\bf How much time is needed to complete experiments (approximately)?: A day and a half.}
  % \item {\bf Publicly available?: Yes.}
  % \item {\bf Code licenses (if publicly available)?: }
  % \item {\bf Data licenses (if publicly available)?: }
  % \item {\bf Workflow framework used?: }
  % \item {\bf Archived (provide DOI)?: }
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Description}

\subsubsection{How to access}

The artifacts are available on GitHub, \url{https://github.com/mxz297/dyninst/tree/layout_opt}.

% {\em Obligatory}

\subsubsection{Hardware dependencies}

For x86_64 binary rewriting, we recommend a 64GB memory.

\subsubsection{Software dependencies}

(1) For x86\_64 arch, we recommend a GCC version 7.3.0 or 7.5.0;

(2) For ppc64le arch, we recommend gcc 6.4.0; 

(3) For aarch64 arch, we recommend gcc 6.4.0.


% \subsubsection{Data sets}

% \subsubsection{Models}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Installation}

% {\em Obligatory}

You can get the artifacts from GitHub and its dependencies using the following
command:

git clone https://github.com/StanPlatinum/ShadowGuard.git

cd ShadowGuard

./bazel.sh deps


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment workflow}

The overall workflow consists of the following steps:

1. Install the artifact and dependencies;

2. Set environment variables;

3. Build the benchmarks;

4. Rewrite the benchmarks;

5. Run the benchmarks.

We provide scripts for each of the steps above.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Evaluation and expected result}

% {\em Obligatory}

We will go through the entire experiment workflow by describing all the commands in each step.

We provide two rewriting mode, \textit{funcptr} mode and \textit{jumptable} mode.

\subsubsection{Micro-benchmark}

SPEC2017.

\subsubsection{Macro-benchmarks}

As described in our paper, several and macro-benchmarks are tested. Here we demonstrate how Firefox and Docker binary can be rewrited by our tool.

Firefox.



To instrument Firefoxâ€™s libxul.so in \textit{funcptr} mode, 

Docker.

Docker Installation guide can be found at \url{https://docs.docker.com/engine/install/ubuntu/}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment customization}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Notes}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Methodology}

% Submission, reviewing and badging methodology:

% \begin{itemize}
%   \item \url{https://www.acm.org/publications/policies/artifact-review-badging}
%   \item \url{http://cTuning.org/ae/submission-20201122.html}
%   \item \url{http://cTuning.org/ae/reviewing-20201122.html}
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% When adding this appendix to your paper, 
% please remove below part
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
