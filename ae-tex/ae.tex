% LaTeX template for Artifact Evaluation V20201122
%
% Prepared by 
% * Grigori Fursin (cTuning foundation, France) 2014-2020
% * Bruce Childers (University of Pittsburgh, USA) 2014
%
% See examples of this Artifact Appendix in
%  * SC'17 paper: https://dl.acm.org/citation.cfm?id=3126948
%  * CGO'17 paper: https://www.cl.cam.ac.uk/~sa614/papers/Software-Prefetching-CGO2017.pdf
%  * ACM ReQuEST-ASPLOS'18 paper: https://dl.acm.org/citation.cfm?doid=3229762.3229763
%
% (C)opyright 2014-2020
%
% CC BY 4.0 license
%

\documentclass{sigplanconf}

\usepackage{hyperref}

% for bash commands
\usepackage{listings}
\lstset{
  language=bash,
  % basicstyle=\ttfamily
  basicstyle=\scriptsize
}

\begin{document}


\special{papersize=8.5in,11in}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% When adding this appendix to your paper, 
% please remove above part
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\appendix
\section{Artifact Appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Abstract}

% {\em Obligatory}

Our artifacts consist of an extension to Dyninst (a famous binary transformation framework). 
We use test programs to verify correctness and measure the overhead caused by our approach - incremental CFG patching. The test
program instruments every basic blocks with empty instrumentation, which will trigger relocating all functions.


\subsection{Artifact check-list (meta-information)}

% {\em Obligatory. Use just a few informal keywords in all fields applicable to your artifacts
% and remove the rest. This information is needed to find appropriate reviewers and gradually 
% unify artifact meta information in Digital Libraries.}

A SPEC2017 benchmark suite is needed for this Artifact Evaluation.

{\small
\begin{itemize}
  % \item {\bf Algorithm: }
  % \item {\bf Program: }
  \item {\bf Compilation: GCC and binary rewriting tools.}
  \item {\bf Transformations: Binary rewriting using Dyninst.}
  \item {\bf Binary: Linux ELF.}
  % \item {\bf Model: }
  % \item {\bf Data set: }
  \item {\bf Run-time environment: Root access to Ubuntu Linux. We recommend Ubuntu Bionic 18.04.}
  % \item {\bf Hardware: }
  % \item {\bf Run-time state: }
  % \item {\bf Execution: }
  \item {\bf Metrics: We use execution time as one of the metrics.}
  \item {\bf Output: For SPEC2017 benchmark, the results are printed into a text file. For web-browser-based benchmarks, results are shown on the browser.}
  \item {\bf Experiments: Using Bash scripts and Linux commands.}
  \item {\bf How much disk space required (approximately)?: 5GB.}
  \item {\bf How much time is needed to prepare workflow (approximately)?: One hour.}
  \item {\bf How much time is needed to complete experiments (approximately)?: A day and a half.}
  % \item {\bf Publicly available?: Yes.}
  % \item {\bf Code licenses (if publicly available)?: }
  % \item {\bf Data licenses (if publicly available)?: }
  % \item {\bf Workflow framework used?: }
  % \item {\bf Archived (provide DOI)?: }
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Description}

\subsubsection{How to access}

The artifacts are available on GitHub, \url{https://github.com/mxz297/dyninst/tree/layout_opt}.

% {\em Obligatory}

\subsubsection{Hardware dependencies}

Since our approach is quite general, it does not need any specific hardware dependencies. 
However, here we list the experimental setup in our paper, for better reproducing the test results.

For x86\_64 binary rewriting, we recommend a 64GB memory.

For ppc64le, we

For aarch64 arch, we

\subsubsection{Software dependencies}

Our artifact is written in C/C++, so it should be built with a C/C++ compiler.

For x86\_64 arch, we recommend a GCC version 7.3.0 or 7.5.0;

For ppc64le arch, we recommend gcc 6.4.0; 

For aarch64 arch, we recommend gcc 6.4.0.


% \subsubsection{Data sets}

% \subsubsection{Models}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Installation}

% {\em Obligatory}

You can get the artifacts from GitHub and its dependencies according to the detailed README file at
\url{https://github.com/mxz297/Incremental-CFG-Patching-ASPLOS21-AE}.
%using the following commands.


% \noindent See the following command :
% \begin{lstlisting}[language=bash]
%   $ wget http://tex.stackexchange.com
%   git clone https://github.com/StanPlatinum/ShadowGuard.git
%   cd ShadowGuard
%   ./bazel.sh deps
% \end{lstlisting}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment workflow}

The overall workflow consists of the following steps:

1. Install the artifact and dependencies;

2. Set environment variables;

3. Build the benchmarks;

4. Rewrite the benchmarks;

5. Run the benchmarks.

We provide scripts for each of the steps above.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Evaluation and expected result}

% {\em Obligatory}

Here we go through the entire experiment workflow in each step.

Our artifact is general and arch-independent. We demonstrate how it can rewrite micro-
and macro- benchmarks at x86\_64 as an example. Experiments and results on other architectures will be
updated continuously on our AE Github repository.


% We provide different rewriting modes, \textit{funcptr} mode and \textit{jumptable} mode 
% for rewriting Firefox.

\subsubsection{Micro-benchmark}

SPEC2017.

\subsubsection{Macro-benchmarks}

As described in our paper, several and macro-benchmarks are tested. 
Here we demonstrate how Firefox and Docker binary can be rewrited by our tool.

Anyone can build the tool using the above-mentioned commands.
Then our rewriting tool `BlockTrampoline' can be found at current directory.
After that, environment variables can be set using a `prep.sh' bash script.

% \begin{lstlisting}[language=bash]
%   git clone https://github.com/StanPlatinum/BlockTrampoline.git
%   cd BlockTrampoline
%   ./prep.sh
%   make
% \end{lstlisting}

\vspace{2pt}\noindent\textbf{Firefox rewriting}. 
Still, we provide two modes to rewrite the libxul.so.

Firefox (version 80.0) is usually shipped with the latest Ubuntu 18.04 dist. 
To install it manually, one can visit \url{https://support.mozilla.org/en-US/kb/install-firefox-linux} and choose the version 80.0 for this evaluation.


To instrument Firefoxâ€™s libxul.so in different modes, we provide a Makefile.
Anyone can instrument libxul.so using different `make' commands. 
For example, using `make firefox-funcptr' for \textit{funcptr} mode. 
% \begin{lstlisting}[language=bash]
%   make firefox-funcptr
% \end{lstlisting}

% \begin{lstlisting}[language=bash]
%   make firefox-jumptable
% \end{lstlisting}

Please be noted that binaries `libxul.so.funcptr' and `libxul.so.jumptable' will be generated at the current directory. 
Then, replace the original libxul.so with them respectively when evaluating different modes.


\vspace{2pt}\noindent\textbf{Firefox evaluation}.

We provide two web-browser-base benchmarks for evaluation.

\vspace{1pt}\noindent$\bullet$\textit{~Web Latency Benchmark}.

Benchmark Installation.

\begin{lstlisting}[language=bash]
wget http://google.github.io/latency-benchmark/latency-benchmark-linux.zip
unzip latency-benchmark-linux.zip
\end{lstlisting}

Run Web Latency Benchmark.

\begin{lstlisting}[language=bash]
./latency-benchmark
\end{lstlisting}

\vspace{1pt}\noindent$\bullet$\textit{~Jetstream2 Benchmark}.

Benchmark Installation.

Type https://browserbench.org/JetStream/ in Firefox search box.

Run Jetstream2.

Click the `Start Test' button.

\vspace{2pt}\noindent\textbf{Docker executable rewriting}

Docker Installation guide can be found at \url{https://docs.docker.com/engine/install/ubuntu/}.

\begin{lstlisting}[language=bash]
make docker
\end{lstlisting}

A new docker binary `docker.inst.bak' will be generated at the current directory. Replace the original docker binary (at /usr/bin/docker) with it.

\vspace{2pt}\noindent\textbf{Docker executable evaluation}.

Simply run the `run.sh' at to test the rewrited docker executable.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Experiment customization}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Notes}

Please exercise with cautions when replacing original binaries (e.g., libxul.so and docker). Always prepare a backup for the evaluation.

The `Image loading jank' cannot be measured in the stable versions of Firefox (79.0 and 80.0) by Web Latency Benchmark.


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Methodology}

% Submission, reviewing and badging methodology:

% \begin{itemize}
%   \item \url{https://www.acm.org/publications/policies/artifact-review-badging}
%   \item \url{http://cTuning.org/ae/submission-20201122.html}
%   \item \url{http://cTuning.org/ae/reviewing-20201122.html}
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% When adding this appendix to your paper, 
% please remove below part
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
